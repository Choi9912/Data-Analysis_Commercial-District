{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e79256b",
   "metadata": {},
   "source": [
    "### 해당 모델 관련한 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ad8b6e",
   "metadata": {},
   "source": [
    "**GBT (Gradient Boosting Tree)**\n",
    "- 부스팅 기법의 하나인 GBM(gradient boosting machine)을 결정 트리에 적용한 앙상블 모델\n",
    "- 회귀, 분류에 모두 적용 가능\n",
    "- 이전 단계에서 학습하지 못한 잔차를 새로운 목표 변수로 두고 학습  \n",
    "$y \\leftarrow h_1(x)$  \n",
    "$y - h_1(x) \\leftarrow h_2(x)$  \n",
    "$y - h_1(x) - h_2(x) \\leftarrow h_3(x)$  \n",
    "$y - \\displaystyle\\sum_{m=1}^{M-1} h_m(x) \\leftarrow h_M(x)$\n",
    "$$\\hat{y} = \\displaystyle\\sum_{m=1}^{M}h_m(x)$$\n",
    "- 이 아이디어에 기반하여, 실제 최적화 된 해를 계산할 때는 경사 하강법을 이용함\n",
    "---\n",
    "1. GBT 회귀\n",
    "- 직렬로 학습하는 가산 모델\n",
    "- 그리디 알고리즘 방식으로 진행\n",
    "- 손실함수는 제곱 오차 손실 또는 절대 오차 손실로 정의된다.\n",
    "---\n",
    "2. GBT 분류\n",
    "- GBT 회귀 모델에서의 예측값 $F_m(x_i) = \\sum h_m(x_i)$를 클래스 또는 클래스의 확률 값으로 변환하는 과정을 추가로 진행해야 한다.\n",
    "- 변환 방법은 손실 함수에 따라 달라진다.\n",
    "- 약학 학습기 $h_m$은 분류 모델이 아니라 여전히 회귀 모델이라는 사실을 명심해야 한다.\n",
    "    - 이는 예측하고자 하는 값이 연속값인 그레이디언트기 때문!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "444b76c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T03:27:57.393476Z",
     "start_time": "2023-12-14T03:27:56.888095Z"
    }
   },
   "outputs": [],
   "source": [
    "# 부스팅 트리 회귀 모델 구현하기\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "df = load_diabetes(as_frame=True)['frame']\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.33,\n",
    "                                                   random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "469772f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T03:29:40.313944Z",
     "start_time": "2023-12-14T03:29:40.047452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터셋 기준 MAE : 54.282\n"
     ]
    }
   ],
   "source": [
    "y_train2 = y_train.copy()\n",
    "\n",
    "trees = []\n",
    "for i in range(100):\n",
    "    reg = DecisionTreeRegressor(max_depth=4,\n",
    "                               random_state=1234).fit(X_train, y_train2)\n",
    "    y_pred = reg.predict(X_train)\n",
    "    y_train2 = y_train2 - y_pred\n",
    "    trees.append(reg)\n",
    "\n",
    "y_pred = np.zeros(len(y_test))\n",
    "for tree in trees:\n",
    "    y_pred += tree.predict(X_test)\n",
    "\n",
    "print(f'테스트 데이터셋 기준 MAE : {(np.abs(y_pred - y_test)).mean():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd0eefc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T03:31:55.571127Z",
     "start_time": "2023-12-14T03:31:55.456067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT 테스트 데이터셋 기준 MAE : 45.110\n",
      "결정트리 테스트 데이터셋 기준 MAE :59.171\n"
     ]
    }
   ],
   "source": [
    "# GradienBosstingRegressor 클래스로 모델 성능 평가\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "reg = GradientBoostingRegressor(n_estimators=100,\n",
    "                               max_depth=4,\n",
    "                               random_state=1234)\n",
    "\n",
    "y_pred = reg.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(f'GBT 테스트 데이터셋 기준 MAE : {(np.abs(y_pred - y_test)).mean():.3f}')\n",
    "\n",
    "y_pred = DecisionTreeRegressor(random_state=1234).fit(X_train, y_train).predict(X_test)\n",
    "print(f'결정트리 테스트 데이터셋 기준 MAE :{(np.abs(y_pred - y_test)).mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58639b8c",
   "metadata": {},
   "source": [
    "### 해당 모델 파라미터 내용  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fed48ad",
   "metadata": {},
   "source": [
    "1. 주요 하이퍼 파라미터\n",
    "- loss : 손실 함수 선택\n",
    "    - 'squared_error' : 제곱 오차 손실 사용\n",
    "    - 'absolute_error' : 절대 오차 손실 사용\n",
    "    - 'huber' : Huber 손실 사용 (L1과 L2의 장점을 합친 손실함수)\n",
    "    - 'quantile' : 분위수 손실 사용\n",
    "- learning_rate : 모든 규제를 위해 각 부스팅 단계에 적용하는 학습률\n",
    "- n_estimators : 부스팅 단계의 수\n",
    "- subsample : 모델의 규제를 위해 각 트리를 만들 때 전체 데이터 대신 subsample의 비율만을 랜덤 샘플링 하여 사용.\n",
    "---\n",
    "2. 조기 종료 로직\n",
    "- validation_fraction : 조기 종료를 위해 사용할 검증 데이터셋 비율\n",
    "- n_iter_no_change : 조기 종료를 적용하고자 모니터링할 이터레이션의 횟수\n",
    "- tol : 조기 종료를 위한 허용 오차 (float)\n",
    "---\n",
    "3. 분류 모델에서 loss 하이퍼파라미터\n",
    "- loss : 손실함수 선택\n",
    "    - 'log_loss' : defualt\n",
    "    - 'exponential'\n",
    "---\n",
    "4. 실제 활용 팁\n",
    "- 모델 복잡도가 증가하는 n_estimators와 모델을 규제하는 learning_rate, subsample 등 상충관계에 있으므로 적절히 선택해야 한다.\n",
    "- 일반적으로 성능에 가장 영향을 끼치는 중요한 하이퍼파라미터 **우선 고려**\n",
    "    - n_estimators\n",
    "    - learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f9147",
   "metadata": {},
   "source": [
    "### 해당 모델 관련 예시 코드 ( 타이타닉 ,,,등등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df7f9adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T04:12:09.947618Z",
     "start_time": "2023-12-14T04:12:09.929119Z"
    }
   },
   "outputs": [],
   "source": [
    "# GBT회귀 클래스 적용하기\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "df = load_diabetes(as_frame=True)['frame']\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   test_size=0.33,\n",
    "                                                   random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb4141d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T04:12:22.027494Z",
     "start_time": "2023-12-14T04:12:21.790289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.318624016786984"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = GradientBoostingRegressor(n_estimators=200,\n",
    "                               learning_rate=0.05,\n",
    "                               max_depth=5,\n",
    "                               random_state=1234).fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse**0.5\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f47b986",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T04:16:59.464271Z",
     "start_time": "2023-12-14T04:16:59.335879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.20052077398064"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = GradientBoostingRegressor(n_estimators=100,\n",
    "                               learning_rate=0.05,\n",
    "                               max_depth=5,\n",
    "                               random_state=1234\n",
    "                               ).fit(X_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse**0.5\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8808f0",
   "metadata": {},
   "source": [
    "### 적고싶은 내용 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0598efc",
   "metadata": {},
   "source": [
    "- 공부하다가 이해 안되는 내용..등등"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
